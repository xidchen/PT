# !pip install cpm_kernels sentencepiece transformers
# It works on Colab T4

import transformers


model_path = "THUDM/chatglm3-6b"

tokenizer = transformers.AutoTokenizer.from_pretrained(
    pretrained_model_name_or_path=model_path,
    trust_remote_code=True,
)

model = transformers.AutoModelForCausalLM.from_pretrained(
    pretrained_model_name_or_path=model_path,
    trust_remote_code=True,
).half().cuda()
model = model.eval()


def extract_quotes(s: str) -> str:
    """Extract quotes between parentheses and after closing parenthesis"""
    quotation_marks = {"\"", "\'"}
    for qm in quotation_marks:
        if s.count(qm) == 2:
            left_qm_index = s.index(qm)
            right_qm_index = s.index(qm, left_qm_index + 1)
            if s.endswith(qm):
                s = s[left_qm_index + 1:right_qm_index]
            else:
                s = s[left_qm_index + 1:right_qm_index] + s[right_qm_index + 1:]
        while qm in s:
            s = s.replace(qm, __new="")
    return s


def extract_chinese_quotes(s: str) -> str:
    """Extract quotes between chinese parentheses and after closing parenthesis"""
    left_qm, right_qm = "â€œ", "â€"
    left_qm_index = s.index(left_qm) if left_qm in s else - 1
    right_qm_index = s.index(right_qm) if right_qm in s else len(s)
    if s.endswith(right_qm):
        s = s[left_qm_index + 1:right_qm_index] + s[right_qm_index + 1:]
    else:
        s = s[left_qm_index + 1:right_qm_index]
    return s


def process_bracket(s: str) -> str:
    """Remove contents in brackets"""
    left_bkt, right_bkt = "(", ")"
    if left_bkt in s or right_bkt in s:
        while left_bkt in s and right_bkt in s:
            left_bkt_index = s.index(left_bkt)
            right_bkt_index = s.index(right_bkt, left_bkt_index + 1)
            s = s[:left_bkt_index] + s[right_bkt_index + 1:]
        if (left_bkt in s) == (right_bkt not in s):
            s = ""
    return s


def process_chinese_bracket(s: str) -> str:
    """Remove chinese contents in brackets"""
    left_bkt, right_bkt = "ï¼ˆ", "ï¼‰"
    if left_bkt in s or right_bkt in s:
        while left_bkt in s and right_bkt in s:
            left_bkt_index = s.index(left_bkt)
            right_bkt_index = s.index(right_bkt, left_bkt_index + 1)
            s = s[:left_bkt_index] + s[right_bkt_index + 1:]
        if (left_bkt in s) == (right_bkt not in s):
            s = ""
    return s


def process_colon(s: str) -> str:
    """Extract content after colon unless exception"""
    colon = "ï¼š"
    while colon in s:
        colon_index = s.index(colon)
        s = s[colon_index + 1:]
    return s


def remove_carriage_return(s: str) -> str:
    """Remove carriage return"""
    s = s.replace("\n", "").replace("\r", "")
    return s


def deduplicate_input(s: str, s_input: str) -> str:
    """Deduplicate input from the output"""
    if s_input in s:
        s = s.replace(s_input, "")
    return s


def remove_starting_punctuation(s: str) -> str:
    """Remove starting punctuations from the output"""
    punctuations = {"ï¼Œ", ",", "ã€‚", "ï¼", "ï¼Ÿ"}
    if s and s[0] in punctuations:
        s = s[1:].strip()
    return s


def remove_hashtag_loop(s: str) -> str:
    """remove hashtags until no hashtags"""
    hashtag = "#"
    while hashtag in s:
        s = remove_one_hashtag(s)
    return s


def remove_one_hashtag(s: str) -> str:
    """Remove one hastag at a time"""
    hashtag = "#"
    exception_chars = {"ï¼Œ", "@"}
    if hashtag in s:
        hashtag_index = s.index(hashtag)
        s_before_hashtag = s[:hashtag_index]
        for char_index in range(hashtag_index, len(s)):
            if s[char_index] in exception_chars:
                s_after_hashtag = s[char_index:]
                s = s_before_hashtag + s_after_hashtag
                return s
        s = s_before_hashtag
    return s


def customize_output(s: str) -> str:
    """Customize generated output, and remove redundant characters"""
    s = extract_quotes(s)
    s = extract_chinese_quotes(s)
    s = process_bracket(s)
    s = process_chinese_bracket(s)
    s = process_colon(s)
    s = remove_carriage_return(s)
    s = remove_starting_punctuation(s)
    s = remove_hashtag_loop(s)
    return s


def produce_response(tknzer, request) -> str:
    response, history = model.chat(tknzer, request, history=[])
    response_word_limit = [1, 100]
    while (
        not isinstance(response, str) or
        len(response) <= response_word_limit[0] or
        len(response) >= response_word_limit[1]
    ):
        response, history = model.chat(tknzer, request, history=[])
    return response


def customize_prompt(acc: str, cs: str, s_1: str, s_2: str) -> str:
    """Customize prompt by inserting a few strings"""
    prompt = (
        f"è¯·ä»¥ä¸€ä¸ªæ™®é€šäººçš„è§’è‰²ä»¥è§†é¢‘æ–‡æ¡ˆä¸ºèƒŒæ™¯ï¼Œ"
        f"é’ˆå¯¹è¯„è®ºå†…å®¹å›å¤è¡¨ç¤ºç§¯æçœŸè¯šåˆç›¸äº’é¼“åŠ±å†…å®¹çš„ä¸€ä¸ªç®€çŸ­çš„å¥å­ï¼Œ"
        f"è¶ŠçŸ­è¶Šå¥½æœ‰åˆ›æ„ï¼Œå’Œè¯„è®ºå†…å®¹äº§ç”Ÿå…±é¸£ã€‚ä¸è¦é‡å¤è§†é¢‘æ–‡æ¡ˆã€‚ä¸è¦é‡å¤è¯„è®ºå†…å®¹ã€‚"
        f"{acc}å…¨ä¸­æ–‡ã€‚{cs}è§†é¢‘æ–‡æ¡ˆæ˜¯\"{s_1}\"ï¼Œè¯„è®ºå†…å®¹æ˜¯\"{s_2}\"ã€‚"
    )
    return prompt


def fail_final_check(s: str) -> bool:
    """Check whether the response fails to pass the final check"""
    fail, not_fail = True, False
    if fail_language_check(s):
        return fail
    if fail_punctuation_check(s):
        return fail
    return not_fail


def fail_language_check(s: str, languages=None) -> bool:
    """Check whether the response fails to pass the language check"""
    if languages is None:
        languages = {"zh"}
    fail, not_fail = True, False
    if languages == {"zh"}:
        for char in s:
            if is_cjk_character(char):
                return not_fail
    return fail


def is_cjk_character(char: str) -> bool:
    """Check whether a character is a CJK character"""
    return True if int(0x4e00) <= ord(char) <= int(0x9fff) else False


def fail_punctuation_check(s: str) -> bool:
    """Check whether the response fails to pass the punctuation check"""
    fail, not_fail = True, False
    wrong_combinations = {"ï¼Œï¼Ÿ", "@ï¼"}
    for combination in wrong_combinations:
        if combination in s:
            return fail
    return not_fail


def print_responses(s_acc, cs, s_1, s_2_list):
    """Print responses by providing acc and a sentence and a list of sentences"""
    reproduction_number = 1
    for s_2 in s_2_list:
        request = customize_prompt(s_acc, cs, s_1, s_2)
        for _ in range(reproduction_number):
            response = produce_response(tokenizer, request)
            response = customize_output(response)
            while fail_final_check(response):
                response = produce_response(tokenizer, request)
                response = customize_output(response)
            print(response)
        print()


acc_content = ""
cs_contempt = ""
video_content = (
    "è‡ªå·±ä¸åŠªåŠ›ï¼Œæ²¡äººä¼šå¸®ä½ ï¼Œèµ°å¥½è‡ªå·±çš„è·¯ã€‚ä¸ç®¡ä»€ä¹ˆå¹´çºªï¼Œåˆ«è¾œè´Ÿæœ€å¥½çš„è‡ªå·±ï¼Œ"
    "ä½ æ‰€æµªè´¹çš„ä»Šå¤©ï¼Œæ˜¯è®¸å¤šäººå¥¢æœ›çš„æ˜å¤©ï¼Œæ— è®ºä½ æ­£åœ¨ç»å†ä»€ä¹ˆï¼Œéƒ½è¦è°ƒæ•´å¥½å¿ƒæ€ï¼Œç ¥ç ºå‰è¡Œ"
    "#åšæŒ#èµšé’±#æˆåŠŸ#åŠªåŠ›#ç”Ÿæ´»#åŠ±å¿—#æ­£èƒ½é‡#é€’æ¢¦é©¿ç«™"
)
comment_content_list = [
    "é è‡ªå·±ï¼ åŠ æ²¹ğŸ¥°",
    "æ„Ÿæ©ğŸ™ å¥½",
    "å¯æ˜¯å¥½ç´¯ğŸ˜­...",
    "è¦åŠªåŠ›åŠ æ²¹ æ‰æœƒè‹¦ç›¡ç”˜ä¾†ğŸ¥°",
    "æ²’éŒ¯ï½èªªçš„å¤ªå¥½äº†",
    "åŠªåŠ›ä¸æ˜¯ä¸ºäº†è¶…è¶Šåˆ«äººï¼Œè€Œæ˜¯ç»™è‡ªå·±ä¸€ä¸ªäº¤ä»£ã€‚ç¾å¥½çš„ä¸œè¥¿ä»ä¸è½»æ˜“è·å¾—ï¼ŒæˆåŠŸé çš„ä¸æ˜¯è±ªè¨€å£®è¯­ï¼Œè€Œæ˜¯è„šè¸å®åœ°çš„åŠªåŠ›ã€‚",
    "æ˜¯çš„ï¼Œä¸åœçš„æå‡è‡ªå·±",
    "å¯¹ï¼ŒåŠ æ²¹ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘",
    "å°ä¸èƒ½é èª°åªèƒ½é è‡ªå·±",
]

print_responses(acc_content, cs_contempt, video_content, comment_content_list)


acc_content = "å¶å°”å¯ä»¥åœ¨ç»“å°¾ç•™ä¸‹è”ç³»æ–¹å¼@{}ï¼Œè®©å¯¹æ–¹å…³æ³¨".format("8237ak")
cs_content = ""
video_content = "å°±å·®ä½ äº†#èµšé’±#èµšé’±çš„æ–¹æ³•#ç°äº§åé—¨#å…¼èŒå‰¯ä¸š#åé—¨é¡¹ç›®#æåé—¨"
comment_content_list = [
    "æ—¥å››ä½æ•°ï¼Œå…è´¹å¸¦",
    "æ±‚å¸¦",
    "å…è´¹å¸¦ä½ ",
    "æœ‰äººèƒ½å¸¦å¸¦æˆ‘å—ï¼Ÿ",
]

print_responses(acc_content, cs_content, video_content, comment_content_list)


acc_content = "å¶å°”å¯ä»¥åœ¨ç»“å°¾ç•™ä¸‹è‡ªå·±è”ç³»æ–¹å¼@{}ï¼Œå¼•èµ·å¯¹æ–¹å…³æ³¨".format("iuwqi")
cs_content = ""
video_content = (
    "Share a zero-cost profitable project suitable for Malaysians. "
    "é›¶æˆæœ¬åˆ›ä¸šé¡¹ç›®åˆ†äº«ï¼Œé€‚åˆğŸ‡²ğŸ‡¾çš„æœ‹å‹ã€‚#èµšé’± #å‰¯ä¸š #å•†ä¸šæ€ç»´ #æ¸¸æˆæ¨å¹¿ #tiktokèµšé’±"
)
comment_content_list = [
    "ä½ å¬è¿‡Amway å—",
    "æœ‰é¡¹ç›®å— æ±‚å¸¦",
    "please å•¦ ï¼ï¼ï¼ å¦‚æœèƒ½,ä½ è€æ—©å°±å˜å¤§è€æ¿ è¿˜å‚»å‚»åœ¨è¿™é‡Œæ‹æŠ–éŸ³TikTok ğŸ˜‚ğŸ˜‚ğŸ˜‚",
]

print_responses(acc_content, cs_content, video_content, comment_content_list)


acc_content = "å¶å°”å¯ä»¥åœ¨ç»“å°¾ç•™ä¸‹è‡ªå·±è”ç³»æ–¹å¼@{}ï¼Œå¼•èµ·å¯¹æ–¹å…³æ³¨".format("ua090")
cs_content = ""
video_content = "åœ¨è‚¡å¸‚ç§ç»å…¸å®ç”¨çš„ä¸»åŠ›è§£å¥—æˆ˜æ³•ï¼å¿«æ”¶è—èµ·æ¥ï¼#è‚¡å¸‚ #æŠ•èµ„ #ç‚’è‚¡ #å¹²è´§åˆ†äº« #è´¢ç»"
comment_content_list = [
    "çº¸ä¸Šè°ˆå…µ",
    "ç„¶åä¸€è·¯è·Œåˆ°2å…ƒï¼Œå†ä¹Ÿæ²¡æœ‰æ˜æ˜¾ä¸Šæ¶¨",
    "ä½ è¦æœ‰wä½ æ‡‚10w å¯èƒ½æ˜¯ä¸€è‚¡è€Œä»¥...",
    "é€šå¸¸ä¸€è³£å°±æ¼²åœ",
    "è·Œç©¿äº†æ€ä¹ˆåŠ",
    "æƒ³çš„æŒºç¾",
    "ğŸ˜å½“ä½ å–åˆæ¼²å›å»äº† ä½ ä¹°è¿›äº†åˆè·Œäº†",
    "è«‹å•å¹¾é»ç¡å¯ä»¥åšé€™éº¼ç¾çš„å¤¢",
    "ğŸ˜…ç•¶å¹´ä¸­è»Šæˆ‘ä¹Ÿæ˜¯é€™æ¨£æ“ä½œï¼Œçµæœã€‚ã€‚ã€‚å”‰ã€‚ã€‚ã€‚",
    "è‚¡ç¥¨ä¸é…åˆæ€éº¼è¾¦",
    "å¯¹äºé‚£äº›æƒ³è¦äº†è§£é‡‘èçŸ¥è¯†çš„äººæ¥è¯´ï¼Œä½ çš„è§†é¢‘æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ„æºï¼",
]

print_responses(acc_content, cs_content, video_content, comment_content_list)


acc_content = "å¶å°”å¯ä»¥åœ¨ç»“å°¾ç•™ä¸‹è‡ªå·±è”ç³»æ–¹å¼@{}ï¼Œå¼•èµ·å¯¹æ–¹å…³æ³¨".format("akl329")
cs_content = ""
video_content = "ä½ è¿˜åœ¨æ‰“å·¥çš„è·¯ä¸Šå—ï¼Ÿè¶Šæ˜¯ç©·è¶Šæ˜¯å›°éš¾çš„æ—¶å€™ï¼Œè¶Šè¦åˆ›ä¸š #åˆ›ä¸š#åˆ›ä¸šé¡¹ç›®#å•†ä¸š#ç”Ÿæ„#å•†ä¸šæ¨¡å¼#å•†ä¸šæ€ç»´"
comment_content_list = [
    "20å¹´å‰ç¡®å®è¡Œå¾—é€šï¼å¯ç°åœ¨æ˜¯21ä¸–çºªäº† å…„å¼Ÿï¼",
    "æ²¡æœ‰å®¢æº ä¸€åˆ‡å…è°ˆã€‚æ²¡æœ‰è®¢å• ä¹Ÿå…è°ˆã€‚",
    "è¯´å¾ˆå®¹æ˜“ï¼Œåšå°±éš¾äº†",
    "ç†è®ºä¸Šå¯ä»¥ï¼Œç°å®æ ¹æœ¬è¡Œä¸é€šï¼Œ",
    "è¯´å½“ç„¶ç®€å•ğŸ˜‚",
    "äº‹å®ä¸Šèƒ½èµšç™¾åˆ†ä¹‹ä¸‰åçš„å·²ç»ç®—æ˜¯åˆ©æ¶¦å¾ˆé«˜çš„äº†",
    "è¦ä¼šåšã€‚å…ˆæ‰“å·¥",
]

print_responses(acc_content, cs_content, video_content, comment_content_list)
